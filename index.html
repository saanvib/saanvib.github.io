<!DOCTYPE html>
<html>
<body>
<h1>Saanvi Bhargava's Homepage</h1>
  <h2>About Me</h2>
  <p>Saanvi Bhargava is a junior at The Harker School in San Jose. Saanvi loves to sing and has been performing since the age of 6. She started learning computer science in middle school and has been recognized for her problem-solving projects in national competitions and in the Synopsis Science Fair. 
    She is the Founder and President of the Beats and Bytes Club, which explores how one can analyze music through technology. 
    Saanvi has been researching how to make music education accessible to more people. 
    Her learnings are published on her <a href="https://medium.com/computational-musicology">blog</a> and all her past projects 
    can be found at her <a href="https://github.com/saanvib">GitHub repo</a>. 
    A talented and trained singer in western classical, she is part of her school’s prestigious show choir group as an alto. 
    In addition to these interests, she is also President-elect for multiple clubs at her school most notably the Future Problem Solving club which focuses on solving practical problems facing our society. 
    She is applying that interest, and her skill in coding and machine learning in exploring how to make music a part of more people’s lives.</p>
  <h2>Recent Research</h2>
  <p>Abstract<p>
    <p>Scalable music education requires giving fast feedback on student audio performances. Current manual feedback mechanisms are given by teachers, rendering them subjective and, therefore, sometimes inaccurate.
      Current technological feedback mechanisms evaluate whether a student is correct on a single note rather than the entire music piece, not providing cumulative or numerical feedback. 
      An AI model is presented for automatically grading vocal music recordings cumulatively on pitch and rhythm given a reference piece of music. 
      The model predicts a numerical grade for the performance of a reference piece of music. The ML model is then tested for accuracy on a dataset of corresponding audio recordings (performance and reference) and tagged human scores for these performances. 
      Besides demonstrating the feasibility of developing an objective music grading system, the investigation presented in this paper also reveals some important limitations and subjectivity of current music grading systems, opening opportunities for future work in the community.</p>
  <a href="A Supervised Learning AI Model for Automated Holistic Vocal Performance Feedback with Figures.pdf">A Supervised Learning AI Model for Automated Holistic Vocal Performance Feedback</a>
  <p>Abstract<p>
    <p>This project seeks to develop a machine learning model to identify deepfakes to prevent the spread of misinformation in this era of technology. 
      Politicians and celebrities are the most affected by deepfakes, since fake videos could endanger their reputation and their careers. 
      Most of the current approaches attempt to create a single model across different videos and using that for detection, which does not yield very accurate results. 
      This study focuses on deepfakes with a single face and attempts to use facial feature extraction for detection of deepfakes. 
      I propose a novel approach of using facial features such as facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation for classification. 
      I conducted 10 different experiments building models for detection using classification algorithms and concluded that 9 of them had an accuracy higher than 95% using the facial feature extraction approach (using OpenFace2). 
      The key finding of this research is that features extracted using the Openface2 library are extremely effective signals for classification of deepfakes involving a single face.</p>
  <a href="ResearchPaperSaanviB0829.pdf">The Role of Facial Features and Mannerisms in Detecting Deepfakes</a>
  

</body>
</html>
